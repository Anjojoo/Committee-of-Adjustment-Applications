---
title: "Understanding Factors Contributing to Application Approval in Urban Planning Decisions (2016-2024)"
subtitle: "Analysis using data from Toronto’s Committee of Adjustment applications using Bayesian Logistic Regression"
author: Angel Xu
thanks: "Code and data are available at: [https://github.com/Anjojoo/Committee-of-Adjustment-Applications](https://github.com/Anjojoo/Committee-of-Adjustment-Applications)."
date: today
date-format: long
abstract: "This paper analyzes urban planning application approvals submitted to Toronto's Committee of Adjustment from 2016 to 2024, focusing on key predictors such as application type, submission year, and planning district using Bayesian logistic regression. The analysis shows that Consents are more likely to be approved than Minor Variances, with approval rates generally increasing over time, particularly from 2017 onward, despite fluctuations in certain years. Geographic disparities were identified, with North York showing the highest likelihood of approval, while Scarborough faced stricter reviews. These findings enhance understanding of urban planning decision-making processes, offering implications into temporal trends, geographic variability, and areas for equitable policy adjustments."
format: pdf
toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(opendatatoronto)
library(modelsummary)
library(knitr)
library(arrow)

analysis_data <- read_parquet(here::here(
  "data/02-analysis_data/analysis_data.parquet"))
```


# Introduction

Urban planning decisions shape the development of cities, influencing how communities grow and adapt to changing social, economic, and environmental conditions. In Toronto, one of Canada’s largest and most diverse cities, the approval of planning applications directly impacts growth, housing availability, and community design. Despite the importance of this process, limited research has explored the specific factors that influence approval decisions, particularly for minor variances and consents. This lack of understanding presents challenges for creating equitable and effective policies that balance the needs of stakeholders while adhering to regulatory frameworks.

This paper examines the factors influencing approval decisions for planning applications submitted to the Committee of Adjustment in Toronto between 2016 and 2024. By analyzing application type, year of submission, and planning district, this study identifies patterns and trends in approval rates. Using a statistical modeling approach, it investigates how administrative processes, policy changes, and regional differences affect these outcomes over time. This analysis addresses a gap in urban planning research, providing a systematic evaluation of the approval process and its determinants.

The findings indicate that consents are more likely to be approved than minor variances, reflecting differences in the scrutiny applied to these application types. Approval rates show notable temporal trends, with the highest approval likelihood observed in 2018, where odds of approval were 161% higher compared to the baseline year of 2016. Significant increases are also evident in 2017 and 2020, with approval rates showing consistent improvement over time, despite some fluctuations. Additionally, geographic disparities are evident, with North York exhibiting the highest approval probabilities, while Scarborough demonstrates lower likelihoods, potentially due to district-specific planning challenges. The difference in approval rates across Toronto’s planning districts suggests localized factors influence decision-making. These results enhance understanding of the approval process and highlight areas where decision-making could become more consistent and equitable.

This study is important because it addresses an area of urban development that has direct implications for policy-making and planning efficiency. By analyzing approval patterns, the research clarifies how procedural factors, geographic contexts, and temporal variations affect outcomes, providing a deeper understanding of the mechanisms at work in planning decisions. This understanding is essential for fostering accountability and ensuring that urban growth aligns with community needs and regulatory frameworks. The findings also serve as a foundation for improving processes and reducing inconsistencies, contributing to more equitable and transparent urban governance.

The remainder of this paper is structured as follows. @sec-data introduces the overview of the data (@sec-data-overview), measurement (@sec-data-measurement), data cleaning process (@sec-data-cleaning), data features (@sec-data-feature), as well as explanations, descriptions, table and graph summaries of outcome (@sec-data-outcome) and predictor variables (@sec-data-predictor) of the study. @sec-model explains the modeling process in detail, including procedure of model set-up, model justifications, model assumptions, and potential limitations. Then, @sec-result highlights the prediction outcome and results by model summary and plots. Finally, @sec-dis includes discussions based on the results, linking it to the real world and also states some weakness of the study. 


## Estimand

This study aims to identify the factors influencing approval decisions for urban planning applications in Toronto. By analyzing variables such as the type of application (minor variance or consent), the year of submission, and the planning district, this study seeks to understand how these elements shape the decision-making process. The primary objective is to examine the causal effects of these factors on approval outcomes, thereby offering analysis of the dynamics of urban planning and regulatory processes. 


# Data {#sec-data}

## Overview {#sec-data-overview}

The data about Committee of Adjustment Applications [@committee_application] was extracted from Open Data Toronto [@opendatatoronto]. This dataset focuses on applications submitted to the City of Toronto's Committee of Adjustment, a governing body responsible for reviewing minor variance and consent applications related to land use and development. These applications are submitted by property owners and developers seeking permission to deviate from existing zoning regulations or to subdivide land. The Committee’s decisions—whether to approve or refuse an application—have significant implications for urban development, community planning, and city growth.

The Committee of Adjustment plays a key role in Toronto’s urban planning ecosystem. It ensures that deviations from zoning bylaws align with the city’s broader development objectives, maintaining a balance between flexibility for property owners and adherence to long-term planning goals. The decisions made by the Committee are influenced by various factors, including the type of application, geographic considerations (e.g. planning districts), and the timing of submission. Understanding these decisions enhances comprehension of urban planning dynamics and the regulatory challenges faced by a growing city like Toronto.

The analysis presented in this paper was conducted using R programming language [@citeR]. The `tidyverse` packages [@citetidyverse], `dplyr` package [@citedplyr], and `arrow` package [@citearrow] were utilized for data simulation and testing. After the original raw data was downloaded using the `tidyverse` package [@citetidyverse], and `dplyr` package [@citedplyr], data cleaning process was carried out using `tidyverse` package [@citetidyverse], `dplyr` package [@citedplyr], and `arrow` package [@citearrow]. The code style was corrected by `here` package [@citehere], `lintr` package [@citelintr], and `styler` package [@citestyler]. Subsequently, models were constructed using `tidyverse` package [@citetidyverse], and `rstanarm` [@citerstanarm] package. Graphs were generated with `ggplot2` package [@citeggplot] and `tidybayes` package [@citetidybayes]. Tables were created with `knitr` package [@citeknitr]. The model results were presented by `modelsummary` [@citemodelsummary] package.

Following @tellingstories, this paper employs a Bayesian Logistic Model to explore factors that affect the application results.

Although several similar datasets with overlapping themes were considered but ultimately not used due to limitations in scope, structure, or relevance. For instance, the Toronto Application Information Centre Dataset provides information on broader planning applications like rezoning requests and site plan approvals, but its complexity and inclusion of unrelated application types made it unsuitable for isolating patterns related to minor variances and consents. The Ontario Municipal Board (OMB) Decisions Dataset includes appeal outcomes, but its focus on contested cases introduces bias and omits the routine applications central to this study.

Consequently, focusing on the Committee of Adjustment Applications dataset [@committee_application] stands out for its granularity and relevance, enabling a focused analysis of approval trends and their influencing factors, which directly align with the study's goals.


## Measurement {#sec-data-measurement}
	
The dataset captures information on applications submitted to the City of Toronto’s Committee of Adjustment, providing a structured record of decisions made on zoning variances and consents. This structure reflects Toronto’s well-defined application process. When property owners or developers submit applications to the Committee of Adjustment, they provide detailed information about their project, including its location, purpose, and the specific variances or consents requested. These details are reviewed by committee staff and entered into a digital database, ensuring consistency and standardization.

Applications to the Committee of Adjustment are typically submitted by property owners, developers, or their authorized agents (e.g. architects or planners). Eligibility requires ownership or legal rights to the property in question. There are two types of application, minor variance (MV) and consents (CO). Consent applications address land subdivision for developments or sales, while Minor Variance applications request small adjustments to zoning regulations like setbacks or height limits. For consent applications, additional prerequisites include demonstrating compliance with existing zoning bylaws or providing documentation showing that the proposed subdivision aligns with city planning objectives. Minor variance applications, on the other hand, require applicants to show that the requested adjustments are “minor” in nature, do not conflict with broader zoning intentions, and maintain compatibility with the surrounding area. As a result, individuals submitting these applications are often professionals with expertise in urban planning, real estate, or development, or property owners working in consultation with such professionals.

Applications to the Committee of Adjustment can be submitted for properties in Toronto’s defined planning districts: Etobicoke York, North York, Scarborough, and Toronto East York. Each district represents a distinct geographic area within the city, characterized by varying levels of urban density, development patterns, and zoning requirements. The choice of district is determined by the location of the property for which the application is being made.

The dataset captures applications spanning multiple years, reflecting historical patterns and trends in urban development. Applications from earlier years may correspond to a period of slower development or more stringent zoning regulations, while more recent submissions could align with economic growth, population increases, or shifts in city planning priorities. For instance, years coinciding with major municipal initiatives or economic booms may see spikes in application numbers. By including the year of submission, the dataset provides a temporal dimension that connects development trends to broader economic and policy contexts, such as changes in zoning laws or housing demand.

The data collection process begins when property owners or developers submitting applications through a centralized system. Application based surveys are collected. Each application includes essential details, which are systematically verified and recorded by administrative staff. Following public hearings, committee decisions (approval or refusal) are added to the database, completing the data entry process. The dataset is then maintained and regularly published by the City of Toronto, ensuring it remains accessible and accurate for public and analytical use.

The dataset serves as an effective tool for examining urban planning decisions. By distilling real-world phenomena—such as zoning adjustments and land use approvals—into discrete variables, the dataset enables systematic analysis of trends and relationships within Toronto’s regulatory framework. This structured approach ensures that the dataset is both practical for analysis and representative of the detailed processes underlying urban development.


## Data Cleaning {#sec-data-cleaning}

To ensure the dataset was suitable for analysis, several cleaning steps were implemented. First, unused decision outcomes were removed, retaining only applications that were explicitly approved or refused. The `decision` variable was then converted into a binary format, with `1` representing approvals and `0` representing refusals, simplifying its use in modeling.

A new variable, `year`, was constructed by extracting the year from the `in_date` field. This adjustment enabled a clearer examination of temporal trends while preserving the granularity of the original data. Applications from earlier years with minimal counts were excluded to avoid bias and ensure a representative analysis of contemporary decision-making trends.

Additionally, key variables were selected in the cleaned dataset for convenience. More details are provided in the appendix.


## Features {#sec-data-feature}

The dataset provides details of applications submitted to the Committee of Adjustment, focusing on key variables:

- **Decision**: Indicates whether an application was approved or refused.
- **Application Type**: Categorizes the application as either a minor variance or a consent.
- **Year**: The year when the application was submitted.
- **Planning District**: The geographic area within Toronto where the application originated.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-preview
#| tbl-cap: "Preview of Key Variables"

# Show first six rows of the cleaned dataset
analysis_data |>
  head() |>
  kable(booktabs = TRUE, align = "c")
```

The first six rows of the cleaned dataset, displayed in @tbl-preview, offer a clear preview of these key variables.

These variables allow for an in-depth analysis of the factors influencing application decision results and provide a quantitative basis for evaluating trends in urban planning decisions. Specific and further discussion about these variables are included in @sec-data-outcome and @sec-data-predictor.


## Outcome variables {#sec-data-outcome}

The outcome variable, decision, captures whether an application submitted to the Committee of Adjustment was approved (represented as 1) or refused (represented as 0).

```{r}
#| label: fig-decision
#| fig-cap: Distribution of Application Decisions
#| echo: false
#| warning: false
#| message: false

#### Workspace Setup####
library(ggplot2)

#### Plot the distribution of `decision` ####
ggplot(analysis_data, aes(x = factor(decision))) +
  geom_bar(fill = "lightblue", color = "black") +
  geom_text(stat = "count", aes(label = ..count..), vjust = -1.0) +
  labs(
    x = "Decision (0 = Refused, 1 = Approved)",
    y = "Count"
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text = element_text(size = 12)
  )
```

@fig-decision illustrates the distribution of decision outcomes. Out of the total applications, 1,207 (66.5%) were approved, while 607 (33.5%) were refused. This indicates that most applications are approved, suggesting that most requests align with zoning regulations or are deemed acceptable following the committee's review process.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-decision
#| tbl-cap: "Summary Statistics of Decisions"

#### Generate summary statistics for `decision` ####
decision_summary <- analysis_data %>%
  group_by(decision) %>%
  summarize(
    Percentage = paste0(round((n() / nrow(analysis_data)) * 100, 1), "%")
  ) %>%
  mutate(Decision = ifelse(decision == 1, "Approved (1)", "Refused (0)")) %>%
  select(Decision, Percentage)

#### Create a kable table ####
decision_summary %>%
  kable(
    format = "html",
    col.names = c("Decision", "Percentage")
  )
```

@tbl-decision summarizes the approval and refusal rates in the dataset, emphasizing a relatively high likelihood of approval for submitted applications.


## Predictor variables {#sec-data-predictor}

### Application type

The application type variable categorizes each application submitted to the Committee of Adjustment into two types:

- Consent (CO): Requests related to the subdivision of land into separate parcels, often for new developments or property sales.

- Minor Variance (MV): Applications seeking small adjustments to zoning regulations, such as building setbacks, height limits, or lot coverage.

These categories represent distinct regulatory processes. Consents generally require more extensive evaluation than Minor Variances due to their implications on land use.

```{r}
#| label: fig-application-types
#| fig-cap: Distribution of Application Types
#| echo: false
#| warning: false
#| message: false

#### Plot the distribution of `application_type` ####
ggplot(analysis_data, aes(x = factor(application_type))) +
  geom_bar(fill = "lightgreen", color = "black") +
  geom_text(stat = "count", aes(label = ..count..), vjust = -1.0) +
  labs(
    x = "Application Type",
    y = "Count"
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text = element_text(size = 12)
  )
```

@fig-application-types presents the distribution of applications by type. Minor Variances account for the majority of applications which reach to 1371 (75.6%), reflecting the routine nature of these requests in urban development. In contrast, Consents are less frequent, with 443 submissions (24.4%), likely due to their more specific requirements and potential complexity.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-application-type
#| tbl-cap: "Summary Statistics of Application Types"

#### Summary Statistics for Application Type ####
application_summary <- analysis_data %>%
  group_by(application_type) %>%
  summarize(
    Percentage = paste0(round((n() / nrow(analysis_data)) * 100, 1), "%")
  ) %>%
  mutate(Application_Type = ifelse(application_type == "MV",
    "Minor Variance (MV)", "Consent (CO)"
  )) %>%
  select(Application_Type, Percentage)

#### Create a kable table ####
application_summary %>%
  kable(
    format = "html",
    col.names = c("Application Type", "Percentage")
  )
```

@tbl-application-type highlights the prevalence of Minor Variances in the dataset, providing context for their role in urban development.

The relationship between application_type and the outcome variable decision will be explored further to determine if approval rates differ between Minor Variances and Consents. Preliminary trends indicate that Minor Variances may have higher approval rates, potentially due to their less complex nature. Additional analyses may examine whether these patterns vary by planning district or year.


### Year

The year variable represents the year of submission for each application in the dataset. It reflects temporal trends in applications submitted to the Committee of Adjustment. This variable is instrumental in identifying changes in the volume of applications over time, which may reflect policy shifts, urban development trends, or external factors like economic conditions.

```{r}
#| label: fig-year
#| fig-cap: Distribution of Applications Years
#| echo: false
#| warning: false
#| message: false

#### Plot the distribution of `year` ####
ggplot(analysis_data, aes(x = factor(year))) +
  geom_bar(fill = "skyblue", color = "black") +
  geom_text(stat = "count", aes(label = ..count..), vjust = -0.8) + # Move labels higher
  labs(
    x = "Year",
    y = "Count"
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) + # Add extra space above bars
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text = element_text(size = 12)
  )
```

@fig-year illustrates the distribution of applications from 2016 to 2024, with notable fluctuations in annual counts. Fewer applications were submitted from 2016 to 2019, with a steady decline from 198 applications in 2016 to a low of 93 in 2019. This period may reflect a stabilization phase or lower activity in urban development processes. Application counts then increased significantly, peaking at 378 applications in 2023, before declining slightly to 249 in 2024. The rise in 2023 may be due to heightened development activity or easing of restrictions from prior external events, such as the COVID-19 pandemic.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-year
#| tbl-cap: "Summary Statistics of Years"

#### Summary Statistics for Year ####
year_summary <- analysis_data %>%
  group_by(year) %>%
  summarize(
    Percentage = paste0(round((n() / nrow(analysis_data)) * 100, 1), "%")
  ) %>%
  arrange(year)

#### Create a kable table ####
year_summary %>%
  kable(
    format = "html",
    col.names = c("Years", "Percentage")
  )
```

@tbl-year summarizes each year's contribution to the total volume of applications.

The year variable is likely related to the decision outcome and application type. Approval rates may have varied over time, potentially due to shifts in city planning policies or committee priorities. Besides, temporal trends may highlight shifts in the proportion of Minor Variances (MV) versus Consents (CO), reflecting evolving development demands.


### Planning District

The planning district variable identifies the geographic district within Toronto where an application was submitted. The city is divided into four planning districts, each with its own development characteristics and zoning regulations. This variable helps identify spatial trends in application submissions and outcomes, as local policies and priorities can influence decision-making processes.

```{r}
#| label: fig-district
#| fig-cap: Distribution of Planning District
#| echo: false
#| warning: false
#| message: false

#### Plot the distribution of `planning_district` ####
ggplot(analysis_data, aes(x = factor(planning_district))) +
  geom_bar(fill = "coral", color = "black") +
  geom_text(stat = "count", aes(label = ..count..), vjust = -1.0) + # Move labels higher
  labs(
    x = "Planning District",
    y = "Count"
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) + # Add extra space above bars
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1) # Rotate x-axis text
  )
```

@fig-district displays the distribution of applications across four planning districts. North York has the highest number of applications, representing a significant proportion of the dataset. This could reflect the area's high density of development projects or active property owners seeking zoning adjustments. Scarborough has the fewest applications, possibly due to fewer development activities or stricter zoning compliance. Etobicoke York and Toronto East York have moderate numbers of applications, reflecting their roles as active but less prominent districts compared to North York.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-district
#| tbl-cap: "Summary Statistics of Planning Districts"

#### Summary Statistics for Planning District ####
district_summary <- analysis_data %>%
  group_by(planning_district) %>%
  summarize(
    Percentage = paste0(round((n() / nrow(analysis_data)) * 100, 1), "%")
  )

#### Create a kable table ####
district_summary %>%
  kable(
    format = "html",
    col.names = c("Planning Districts", "Percentage")
  )
```

@tbl-district summarizes how applications are distributed spatially across the city.

The planning district variable may also interact with application type and decision. Approval rates may vary by district, reflecting differences in local policies or development dynamics. The proportion of Minor Variances (MV) versus Consents (CO) may differ across districts, indicating distinct development priorities or zoning challenges.


# Model {#sec-model}

In this paper, a Bayesian logistic model is employed to understand how factors such as application type, submission year, and planning district influence the decisions of the application committee. This model estimates the probability of an application being approved (P(Approval)) based on the given predictors.

The goal of this modeling strategy is twofold: (1) to estimate how each predictor affects the likelihood of approval, and (2) to quantify the uncertainty associated with these estimates. This approach accommodates prior knowledge while addressing the hierarchical nature of the predictors, such as geographic regions.

We run the model in R [@citeR] using the `rstanarm` package of @citerstanarm. `rstanarm` [@citerstanarm] is used to set up the model.`tidybayes` package [@citetidybayes] is used to plot predicted probabilities in for result analysis.

Here we briefly describe the Bayesian analysis model used to investigate, and include justification for model and the variables, as well as discuss underlying assumptions, potential limitations, and evidence of model validation and checking.

Additional details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

In the Bayesian logistic regression model, the response variable $y$ follows a Bernoulli distribution, reflecting its binary nature. Coefficients $\beta_k$ (where k=0,1,2,3) of every predictor variables follow a Normal distribution. Specifically:

\begin{align} 
y_i|p_i &\sim \mbox{Bern}(p_i) \\
\beta_0 &\sim \mbox{Normal}(0, 2.5) \\
\beta_1 &\sim \mbox{Normal}(0, 2.5) \\
\beta_2 &\sim \mbox{Normal}(0, 2.5) \\
\beta_3 &\sim \mbox{Normal}(0, 2.5)
\end{align}

Combining all the components, the complete model can be expressed as:

\begin{equation}
\log\left(\frac{p_i}{1 - p_i}\right) = \beta_0 + \beta_1 \times \text{application type} + \beta_2 \times \text{year} + \beta_3 \times \text{planning district}
\end{equation}

- $p_i$: the probability for the binary outcome variable to be 1 (1 = approval, 0 = refusal).
- $\beta_0$: Intercept, representing the baseline log-odds of approval for the reference levels of the predictors.
- $\beta_1$: Coefficients for application type, dummy-coded with CO as the reference category.
- $\beta_2$: Coefficient for year, measured as the year of application to capture temporal trends.
- $\beta_3$: Coefficients for planning district, dummy-coded with North York as the reference category.

In the above Bayesian logistic regression model, the coefficients $\beta = {\beta_0, \beta_1, \beta_2, \beta_3}$ are treated as random variables, each assigned a Normal prior distribution, with a zero mean and 2.5 standard deviation. These priors reflect weakly informative beliefs, expressing no strong assumption about the direction or magnitude of effects while allowing for reasonable variability in the estimates.

The Normal distribution is appropriate for these priors as it assumes most effects are small or moderate, centered around zero, while permitting deviations in either direction. A standard deviation of 2.5 offers a balance between constraining the parameters and allowing the data to influence the estimates. This ensures that the model avoids overfitting, particularly when data is sparse or multicollinearity exists among predictors.

After observing the data, the posterior distributions of $\beta$ are derived by combining the priors with the likelihood of the observed outcomes. These posterior distributions represent updated beliefs about the coefficients, integrating both prior knowledge with evidence from the data. This approach provides robust inference, quantifies parameter uncertainty, and supports detailed interpretations of the predictors' effects.


## Model justification

The Bayesian logistic regression model is suitable for analyzing how application type, submission date, and planning district influence the likelihood of application approval. This choice is driven by the binary nature of the response variable, the model's ability to incorporate prior knowledge, and its probabilistic framework, which effectively quantifies uncertainty than alternatives. Logistic regression naturally constrains predicted probabilities to the [0,1] interval, ensuring interpretability as likelihoods of approval, while the Bayesian approach adds flexibility and provides richer revelations through posterior distributions.

Compared to traditional generalized linear models (GLM), the Bayesian approach allows for the inclusion of prior beliefs through weakly informative priors ($N(0, 2.5)$) for all coefficients. These priors help stabilize the model, particularly in cases where data is sparse or multicollinear, without overwhelming the contribution of the observed data. Additionally, Bayesian methods yield full posterior distributions rather than single-point estimates, offering a clearer view of parameter uncertainty and a better capacity to incorporate uncertainty into decision-making processes. These advantages make the Bayesian logistic regression model preferable to a standard GLM, which provides point estimates and relies on asymptotic approximations for inference.

The model also addresses limitations of simpler methods, such as simple linear regression (SLR). While SLR might be used for binary outcomes in certain contexts, it is theoretically inappropriate because it does not constrain predictions to the [0,1] interval. This can result in nonsensical predicted probabilities outside this range. Moreover, SLR assumes a linear relationship between predictors and the response variable, which is unsuitable for binary outcomes. The logit transformation in logistic regression, by contrast, ensures a proper probabilistic framework and preserves interpretability in terms of log-odds.

The predictors included in the model further justify the choice of Bayesian logistic regression. Application type captures fundamental differences in how various categories of applications, such as minor variances and consents, might affect approval outcomes. Submission date is treated as a continuous variable, reflecting temporal trends without arbitrary grouping, while planning district accounts for geographic variability through categorical indicators. These predictors are naturally suited to a logistic framework, and the Bayesian approach accommodates any inherent variability in their effects.

`Mostly Harmless Econometrics` (@angrist2009mostly) emphasizes addressing variability in time-series and cross-sectional data, focusing on ensuring robust and interpretable results. The inclusion of submission year and planning district as predictors follows Angrist and Pischke's guidance on controlling for time trends and location-specific effects, validating their relevance in this model.

In summary, Bayesian logistic regression offers a robust and transparent framework for analyzing the factors influencing application decisions. Its advantages over GLM and SLR include the ability to incorporate prior information, quantify uncertainty, and handle the non-linear nature of the binary response variable. By balancing methodological rigor with practical transparency, this model ensures that the analysis remains both statistically sound and actionable for stakeholders.


## Model Assumption

This Bayesian model relies on several assumptions to ensure the validity of its predictions and the interpretability of its coefficients. While these assumptions are less restrictive than those for simpler models like linear regression, they remain important to the robustness of the results. The key assumptions are as follows:

1. **Binary Response Variable**
The model assumes that the response variable ($y$) is binary, taking values of either 1 (approval) or 0 (refused). This assumption aligns with the nature of the data, as application decisions are dichotomous. Deviations from binary coding would invalidate the logistic framework and require alternative modeling approaches.

2. **Independence of Observations**
The model assumes that all observations are independent. This is reasonable for application data, as decisions are typically made independently by the committee. However, if clustering or dependence exists (e.g. correlated decisions within the same planning district), the model may require hierarchical or random effects to account for these dependencies.

3. **No Perfect Multicollinearity**
Logistic regression assumes that the predictors are not perfectly correlated, as this would prevent the model from unique coefficients. For example, if a predictor is a linear combination of other predictors, the model would fail to converge. In this analysis, categorical variables of application type and planning district are properly encoded to avoid such issues.

4. **Proper Model Specification**
The model assumes that relevant predictors are included and correctly specified. Omitting important variables or including irrelevant ones could lead to biased estimates or reduced transparency. For example, excluding interaction terms when they are theoretically justified might lead to an incomplete understanding of the predictors' effects.


## Potential Limitation and Addressing Violation

Violations of the above assumptions can impact this model’s validity while several solutions are listed below:

1. **Non-linearity**
Adding polynomial terms or splines could address non-linear relationships if diagnostic checks suggest deviations.

2. **Dependence**
If observations are not independent (e.g. decisions clustered by region), hierarchical models or random effects may be introduced.

3. **Multicollinearity**
Variance inflation factors or correlation matrices can identify multicollinearity issues, which can be resolved by removing or combining correlated predictors.

By adhering to these assumptions and addressing potential violations, the Bayesian logistic regression model offers a reliable framework for analyzing the factors influencing application outcomes.


## Model Validation

To ensure the robustness and reliability of the Bayesian logistic regression model, a series of validation and diagnostic steps was conducted. Detailed plots and results, including posterior predictive checks (PPC), posterior vs. prior comparisons, and convergence diagnostics, are provided in the appendix for further examination. Below, the focus is on key validation method of **out-of-sample testing**:

The dataset was split into a training set (80%) and a test set (20%) to evaluate the model's predictive performance on unseen data. The model was trained on the training set, and predictions were made on the test set. Classification accuracy was calculated as the proportion of correctly classified outcomes in the train set and test set. This approach assesses the model's generalizability.

```{r}
#| echo: false
#| eval: true
#| label: tbl-accuracy
#| tbl-cap: "Classification Accuracy for Model Validation"
#| warning: false

# Load the saved results
accuracy_results <- readRDS(file = here::here("models/accuracy_results.rds"))

# Extract the values
accuracy_train <- accuracy_results$accuracy_train
accuracy_test <- accuracy_results$accuracy_test

#### Summary Statistics for Accuracy ####
accuracy_summary <- tibble(
  `Train Accuracy` = accuracy_train,
  `Test Accuracy` = accuracy_test
)

#### Create a kable table ####
accuracy_summary %>%
  kable(
    format = "html"
  )
```

@tbl-accuracy shows the train and test accuracy. The model's training accuracy of 66.75% and test accuracy of 66.575% are quite close, indicating that the model generalizes reasonably well between the training and test datasets. However, the relatively low accuracy on both datasets suggests underfitting, where the model fails to capture the complexity of the data and adequately explain the variance in the outcomes. This could result from the model being too simplistic, with insufficient predictors or inadequate representation of the data structure. Additional factors, such as noisy or unbalanced data, limited feature engineering, or a lack of higher-order interactions and non-linearities in the model could also contribute to this underfitting.


# Results{#sec-result}

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

model <-
  readRDS(file = here::here("models/first_model.rds"))
```


```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Model results of Application Approval Probability"
#| warning: false

model <- model

modelsummary::modelsummary(
  list(
    "Model" = model
  ),
  statistic = "mad",
  fmt = 2
)
```

The result highlights how the predictors influence the likelihood of application approval while controlling for other variables. The coefficients, presented as log-odds, indicate both the direction and magnitude of each predictor’s impact on approval decisions.

The intercept estimate of -0.06 represents the baseline log-odds of approval for a consent (CO) application submitted in 2016 in Etobicoke York, where all predictors are at their reference levels. This corresponds to a baseline probability close to 0.5, indicating nearly equal odds of approval or refusal in the absence of other influencing factors. This serves as a neutral starting point for understanding how the predictors shift the likelihood of approval.

The variable application_typeMV, with a coefficient of -0.20, suggests that applications for minor variances (MV) are less likely to be approved than consents (CO). In terms of odds, the transition from a consent to a minor variance reduces approval odds by approximately 18% ($e^{-0.20}\approx 0.82$). This aligns with expectations, as minor variances may face stricter scrutiny due to their potentially greater impact on local zoning adjustments.

The year variables demonstrate significant temporal variations in approval likelihood, using 2016 as the reference year. These coefficients highlight how approval dynamics have shifted over time. In 2017, the coefficient of 0.74 indicates a 109% increase in the odds of approval compared to 2016 ($e^{0.74} \approx 2.09$), which suggests a substantial policy or procedural shift. In 2018, the strongest positive effect is observed, with a coefficient of 0.96, reflecting a 161% increase in odds relative to 2016 ($e^{0.96} \approx 2.61$). However, in 2019, the coefficient drops to 0.22, representing a smaller increase of 25% ($e^{0.22} \approx 1.25$), suggesting that this period may have faced stricter reviews or procedural adjustments. By 2020, the coefficient rebounds to 0.56, translating to a 75% increase ($e^{0.56} \approx 1.75$).

For more recent years, 2021 shows a coefficient of 0.34, showing a 40% increase in odds ($e^{0.34} \approx 1.40$). In 2022, the coefficient is 0.28, reflecting a 32% increase ($e^{0.28} \approx 1.32$). In 2023, approvals surged again, with a coefficient of 0.99, representing a 170% increase in odds ($e^{0.99} \approx 2.69$). Finally, 2024 showed the highest increase, with a coefficient of 1.24, translating to a 245% increase in approval odds compared to the baseline year of 2016 ($e^{1.24} \approx 3.46$). This upward trend reflects improvements in the approval process, possibly due to increased efficiency, evolving zoning policies, or external influences favoring development.

The model captures geographic variability in approval rates across Toronto’s planning districts. North York, with a coefficient of 0.41, shows a 50% increase in odds compared to Etobicoke York ($e^{0.41} \approx 1.50$), highlighting its role as a development hub with urban growth priorities. Scarborough has the lowest approval likelihood, with a coefficient of 0.16, indicating a modest 17% increase in odds ($e^{0.16} \approx 1.17$), suggesting challenges related to stricter zoning rules or community resistance to changes. Toronto East York has a coefficient of 0.33, showing a 39% increase in odds ($e^{0.33} \approx 1.39$), reflecting its mix of heritage preservation and urban development priorities. The results emphasize localized influences on approval rates due to zoning policies, development pressures, and socio-political factors.

In summary, the model displays how application type and submission year influence the approval likelihood. Minor variance applications face slightly lower odds of approval compared to consents, while temporal trends indicate an overall increase in approval rates from 2016 to 2024. Geographic variability further highlights differences across planning districts. These findings provide a basis for examining factors such as localized dynamics or interactions between predictors.

```{r}
#| label: fig-pp-type
#| fig-cap: Predicted Probability of Approval by Application Type
#| echo: false
#| warning: false
#| message: false

# Load required libraries
library(tidybayes)

# Clean analysis_data to drop unused levels
new_data <- analysis_data %>%
  mutate(
    application_type = factor(application_type),
    year = factor(year),
    planning_district = factor(planning_district)
  )

# Generate prediction data without creating NAs
predict_data <- expand_grid(
  application_type = levels(new_data$application_type),
  year = levels(new_data$year),
  planning_district = levels(new_data$planning_district)
)

# Generate predicted probabilities
posterior_probs <- posterior_epred(model, newdata = predict_data)

# Transpose posterior_probs to match predict_data
posterior_probs_t <- t(posterior_probs)

# Check dimensions for consistency
if (nrow(predict_data) != nrow(posterior_probs_t)) {
  stop("Dimension mismatch between predict_data and posterior_probs.")
}

# Convert predictions to long format for boxplots
predict_data_long <- predict_data %>%
  mutate(row_id = row_number()) %>%
  bind_cols(as_tibble(posterior_probs_t)) %>%
  pivot_longer(cols = starts_with("V"), names_to = "sample", values_to = "prob")

# Plot boxplot for application type
ggplot(predict_data_long, aes(x = application_type, y = prob)) +
  geom_boxplot() +
  labs(
    x = "Application Type",
    y = "Predicted Probability of Approval"
  ) +
  theme_minimal()
```

@fig-pp-type demonstrates variability in the predicted probability of approval between consent applications (CO) and minor variances (MV). Consent applications exhibit a slightly higher median predicted probability of approval compared to minor variances. Both application types have similar interquartile ranges (IQR), but minor variances exhibit a broader lower whisker, reflecting stricter scrutiny for certain cases.

```{r}
#| label: fig-pp-year
#| fig-cap: Predicted Probability of Approval by Year
#| echo: false
#| warning: false
#| message: false

# Generate predicted probabilities for year
ggplot(predict_data_long, aes(x = year, y = prob)) +
  geom_boxplot() +
  labs(
    x = "Year",
    y = "Predicted Probability of Approval"
  ) +
  theme_minimal()
```

@fig-pp-year explores temporal trends in the predicted probability of approval from 2016 to 2024. The median predicted probability of approval rises steadily from 2016 to 2024. While 2016 exhibits the lowest probabilities, years such as 2018 and 2024 display higher medians, indicating increased approval likelihood in recent years. Variability within years remains relatively stable, with slight fluctuations in the spread across the interquartile range. This pattern aligns with findings from the regression analysis, where temporal predictors indicated a gradual improvement in approval rates over time. This likely reflects policy or procedural changes that have positively influenced the decision-making process.

```{r}
#| label: fig-pp-district
#| fig-cap: Predicted Probability of Approval by Planning District
#| echo: false
#| warning: false
#| message: false

# Generate predicted probabilities for planning district
ggplot(predict_data_long, aes(x = planning_district, y = prob)) +
  geom_boxplot() +
  labs(
    x = "Planning District",
    y = "Predicted Probability of Approval"
  ) +
  theme_minimal()
```

@fig-pp-district evaluates geographic variability in approval probabilities across the four planning districts. North York consistently shows the highest median predicted probability of approval, reaffirming its development hub with favorable zoning outcomes. Scarborough has the lowest median and a wider spread of probabilities, with outliers indicating challenging cases. Toronto East York and Etobicoke York present intermediate medians, suggesting more balanced approval probabilities in these regions. These geographic differences highlight the influence of localized development dynamics and zoning considerations on approval outcomes.


# Discussion{#sec-dis}

## Overview

This paper investigates the factors influencing application approvals submitted to the City of Toronto's Committee of Adjustment, using a Bayesian logistic regression model. By analyzing predictors such as application type, submission year, and planning district, the study examines the dynamics of urban planning decisions. The model captures temporal trends, spatial variability, and procedural differences, offering a structured understanding of approval outcomes. Visualizations, including coefficient plots and predicted probability plots, complement the analysis, helping to interpret the relationships between predictors and approval likelihood.

## Temporal Trends in Approval Rates

One key finding is the temporal trend in approval rates. The analysis shows that approval odds have increased steadily over time, peaking in 2018. This trend may reflect evolving planning policies, greater efficiency in committee processes, or a shift in zoning priorities. The data suggests that the Committee of Adjustment has become more permissive in granting approvals, which could indicate a growing alignment between applications and city planning objectives. This result demonstrates how administrative processes adapt over time to urban development needs.

## Geographic Disparities in Approval Decisions

Spatial variability plays a significant role in application approvals. The findings show that North York consistently exhibits the highest approval rates, likely due to its prominence as a development hub with infrastructure supporting large-scale projects. Conversely, Scarborough has the lowest odds of approval, suggesting stricter zoning enforcement or less alignment with development objectives in this area. This geographic disparity underscores the influence of local contexts and priorities on urban planning decisions, manifesting how different districts balance growth and zoning compliance.

## Weaknesses

While this paper analyzes the factors influencing application approvals, several limitations remain. These weaknesses include data-related issues, methodological constraints, and broader contextual considerations.

1. **Data Limitations**
The analysis relies solely on the dataset provided by the City of Toronto's Committee of Adjustment, which, while complete in its coverage of applications, lacks certain important variables. Contextual factors, such as community objections, project complexity, or political and economic pressures, are not captured. For instance, the dataset does not provide information about why certain applications are refused or approved beyond the recorded decision, limiting the ability to analyze qualitative or situational influences.

2. **Methodological Constraints**
The Bayesian logistic regression model assumes that the relationships between predictors and the outcome variable are additive and linear on the log-odds scale. This assumption may oversimplify real-world interactions between variables, such as how specific planning districts may interact with application types or temporal trends. The model's relatively low accuracy for both the training and test datasets suggests underfitting, failing to capture the data complexity and may not adequately explain the variance in outcomes. This could stem from insufficient predictors, unaccounted non-linear relationships, or interactions among variables. Furthermore, the model does not fully account for potential multicollinearity among predictors, which could distort the estimated coefficients. While priors were carefully chosen, their influence on the results might vary with a different prior specification, introducing some degree of subjectivity into the analysis.

3. **Simplified Representation of Approval Dynamics**
The approval process involves a combination of bureaucratic procedures, stakeholder negotiations, and technical considerations that are not fully captured in this analysis. For example, public hearings, lobbying efforts, and input from local communities likely play a significant role in shaping decisions but are absent from the dataset. This simplification means that the model captures only part of the story, potentially overlooking sophisticated dynamics in urban planning and governance.

4. **Geographic and Temporal Generalizability**
The analysis focuses exclusively on the City of Toronto, meaning the findings are context-specific and may not generalize to other municipalities with different urban planning frameworks, policies, or demographic pressures. Temporal trends in approval rates, for example, could be influenced by unique local events or policy changes that are not representative of broader patterns. Similarly, the observed geographic variability in approval rates might reflect Toronto-specific zoning challenges rather than universal principles.


## Nest Steps

Building on the findings and addressing the limitations of this paper, there are several avenues for future research and analysis that could provide a deeper understanding of the factors influencing application approvals in urban planning contexts.

One important next step is to expand the dataset by incorporating additional variables that capture contextual and qualitative factors influencing decisions. Data on community feedback and objections during public hearings is a good choice since it could show how local resistance or support impacts approval likelihood. Information on project complexity, such as the scale, type, and potential impact of proposals, could indicate patterns in decision-making. Besides, access to committee meeting notes or further investigation in meeting minutes would help clarify the reasoning behind specific approvals or refusals. Furthermore, integrating economic and political context, such as local economic indicators or changes in political leadership, would offer a broader understanding of approval trends.

The current model assumes additive relationships between predictors and approval likelihood, which may oversimplify real-world dynamics. Future research could explore nonlinear relationships, such as whether certain predictors have diminishing or exponential effects on approval rates. Interaction effects between predictors, such as the interplay between planning districts and application types, could also provide more subtle observation. For instance, minor variances may be treated differently in densely populated urban areas compared to suburban districts.

Extending this analysis to other municipalities or regions would help determine whether the observed trends in Toronto are unique or indicative of broader urban planning practices. Cross-regional comparisons could identify common principles across jurisdictions, highlight local deviations driven by distinct policies or demographics, and establish benchmarks for understanding how Toronto’s process aligns with other cities. Such studies could enhance the generalizability of findings and provide practical lessons for urban planners in different contexts.

Despite to future improvements for addressing limitations, further examination can be continued based on the current result. The temporal trends identified in this paper suggest shifts in approval rates over time, but the reasons behind these changes remain unexplored. Future work could examine specific policy changes or regulatory updates to understand their impact on approval trends. Additionally, external events such as economic downturns, housing crises, or infrastructure investments could be analyzed for their influence on application volumes and decisions. A difference-in-differences approach could also help isolate the effects of significant policy interventions, providing a clearer picture of causal relationships.

Given the importance of geographic variability in approval rates, future research could adopt spatial analysis techniques. Spatial regression models could account for spatial autocorrelation and clustering effects in planning districts, while network analysis could study relationships between districts, such as spillover effects of development activity. Additionally, analyzing proximity to key infrastructure, such as transit hubs or commercial centers, could provide perceptions into spatial patterns of decision-making.

Finally, the findings from this paper could inform the development of predictive tools to assist urban planners and developers. These tools could provide probabilistic forecasts of approval likelihood based on project attributes and contextual factors. Additionally, they could help committees identify systemic biases or inefficiencies in their decision-making processes and aid policymakers in designing more equitable and transparent approval frameworks.

In summary, future research should prioritize richer data integration, explore more sophisticated modeling techniques, and broaden the scope of analysis to other regions and temporal contexts. These steps would not only enhance academic understanding of urban planning decisions but also provide actionable perceptions for policymakers, developers, and urban planners working toward effective and equitable processes.

\newpage

\appendix

# Appendix {-}


# Additional data cleaning details

The dataset underwent a structured cleaning process to ensure its suitability for analysis, focusing on preparing the data while minimizing bias and enhancing interpretability. Below is a detailed description of the key cleaning steps:

1. **Filtering Unused Decision Outcomes**

The dataset originally included a range of decision outcomes beyond approvals and refusals, such as applications that were deferred or withdrawn. These were excluded to focus solely on cases where the Committee of Adjustment made a definitive decision. This exclusion is done by filtering decisions with "approve", "approval", and "refused" words in it while conditionally approved are all default as approval to enlarge the data size. This ensured a binary structure for the decision variable, aligning with the study’s objectives.

2. **Conversion of decision to Binary Format**

The decision variable was converted into a binary format for consistency and ease of analysis:

1: Representing approved applications.
0: Representing refused applications. This transformation provided a clear and standardized representation of application outcomes.

3. **Creation of the year Variable**

A new variable, year, was created by extracting the year component from the date field. This allowed for an analysis of temporal trends without losing the temporal resolution of the data. The original date variable remained intact for potential use in supplementary analyses.

4. **Filtering Applications from Earlier Years**
Applications before 2016 were removed from the dataset due to their low counts. Retaining these outliers could lead to biased results, particularly in trend analyses or modeling. By excluding these years, the dataset better represents the more recent and consistent patterns of decision-making.

5. **Removing Missing Values**
Records with missing values in the chosen variables (decision, application_type, year, and planning_district) were removed.

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows the model's ability to generate data consistent with the observed data. By overlaying the observed data and simulated replicated datasets  generated from the posterior predictive distribution, we assess the model's adequacy. The close alignment between the observed data and the majority of the simulated replicated datasets indicates that the model captures the underlying structure of the data well. Deviations would signal potential misfits or areas where the model assumptions may need to be revised.

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This comparison highlights how the data influenced parameter estimates. Large shifts from the prior to the posterior, such as seen for certain planning districts and years, suggest strong empirical updates. Conversely, parameters where the posterior closely resembles the prior indicate minimal influence from the observed data. This evaluation helps assess the informativeness of the priors and the robustness of the parameter estimates, ensuring the model is both data- and prior-consistent.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 1
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check",
#| "Comparing the posterior with the prior"]

pp_check(model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(model) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(hjust = 1, vjust = 0.5),
    text = element_text(size = 6)
  ) +
  guides(color = guide_legend(ncol = 6)) +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-trace presents trace plots. It shows the sampled values for each chain of the Markov Chain Monte Carlo (MCMC) simulation over iterations. The chains appear to mix well and explore the parameter space without any evident trends or stickiness, suggesting convergence. The consistent overlap of chains indicates that the posterior distribution has been effectively sampled, reducing the risk of bias due to poor chain mixing or non-convergence.

@fig-rhat is a Rhat plot. It evaluates the Gelman-Rubin convergence diagnostic. All parameters show $\hat{R}$ values close to 1, which indicates that the between-chain and within-chain variances are nearly identical. This confirms that the MCMC chains have converged and are sampling from the same target distribution, validating the reliability of the posterior estimates.

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-trace
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot of Intercept", "Trace plot of Application type MV", "Trace plot of year 2017", "Trace plot of year 2018", "Trace plot of year 2019", "Trace plot of year 2020", "Trace plot of year 2021", "Trace plot of year 2022", "Trace plot of year 2023", "Trace plot of year 2024", "Trace plot of planning district NorthYork", "Trace plot of planning district Scarborough", "Trace plot of planning district EastYork"]
#| layout-ncol: 3

plot(model, "trace", "(Intercept)")
plot(model, "trace", "application_typeMV")
plot(model, "trace", "year2017")
plot(model, "trace", "year2018")
plot(model, "trace", "year2019")
plot(model, "trace", "year2020")
plot(model, "trace", "year2021")
plot(model, "trace", "year2022")
plot(model, "trace", "year2023")
plot(model, "trace", "year2024")
plot(model, "trace", "planning_districtNorth York")
plot(model, "trace", "planning_districtScarborough")
plot(model, "trace", "planning_districtToronto East York")

```

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-rhat
#| fig-cap: "Rhat plot"
#| layout-ncol: 1

plot(model, "rhat")
```


# Idealized Methodology and Survey

## Overview
This section outlines an idealized methodology and survey design to supplement the observational dataset used in this study. The objective is to enhance the analysis of urban planning decisions by incorporating a carefully designed survey targeting key stakeholders in Toronto's zoning and land-use processes.

## Sampling Approach

### Target Population
The target population comprises stakeholders involved in the Committee of Adjustment's decision-making process, including:

- **Property Owners and Developers**: Individuals or entities who submit applications for minor variances or consents.
- **Urban Planners and Architects**: Professionals who prepare applications or advise clients on zoning requirements.
- **Committee Members and Staff**: Officials responsible for evaluating applications and making decisions.
- **Community Members**: Residents who may provide feedback during public hearings.

### Sampling Frame
The sampling frame would be constructed using publicly available application records and contact information from municipal directories. This ensures representation from all planning districts and captures diverse perspectives across geographic and professional domains.

### Sample Size
Using stratified random sampling, the sample size would aim for approximately 3000 respondents, ensuring statistical validity while considering feasibility.

### Stratified Random Sampling
Stratified random sampling enhances the accuracy of survey estimates because it ensures proportional representation of different demographic groups. This minimizes the risk of sampling bias, where certain groups may be overrepresented or underrepresented, skewing the results.

Hence, to achieve a representative sample, stratified random sampling will be employed. This method involves dividing the population into homogeneous subgroups based on key demographic characteristics, then randomly selecting samples from each stratum proportionate to its size in the population. The strata will include:

- Application types: Categorize applicants based on the purpose of their submission. (Minor Variance and Consent)
- Planning districts: Stratify by Toronto's four major planning districts to capture geographic diversity. (North York, Scarborough, Toronto East York, and Etobicoke York)
- Applicant roles: Group participants by their involvement in the application process. (Individual Property Owners, Developers, and Consultants)

Within these strata, respondents will be randomly selected to align with the distribution of these categories in the broader population. The process begins by grouping the population into strata defined by characteristics such as application type, planning district, and applicant role. Afterward, random samples are drawn independently from each subgroup, ensuring proportional representation. In cases where smaller groups are important to the study, adjustments can be made to ensure adequate representation. Finally, the selected samples from each subgroup are combined to create the overall sample, ensuring that all significant categories are included.

`Sampling: Design and Analysis` [@lohr2021sampling] explores how stratified sampling reduces variability by dividing populations into homogeneous groups, enabling more precise estimates and better resource allocation. By applying these principles, the paper ensures that the analysis accounts for heterogeneity in geographic and temporal patterns of planning applications, enabling robust conclusions about decision-making trends. The methodology follows Lohr’s recommendation to tailor strata definitions to the study's objectives, enhancing the reliability of the results.

Besides, `Sampling` [@thompson2012sampling] provides a detailed guide to modern sampling techniques, emphasizing the importance of tailoring approaches to study objectives. His discussion on stratified sampling highlights its benefits in improving precision and reducing bias by dividing populations into homogeneous subgroups. This aligns with the choice of using planning districts, application types, and submission years as strata to ensure balanced representation and capture temporal and spatial variability in urban planning decisions. Thompson’s principles validate the proportional sampling approach adopted here, supporting its effectiveness in generating reliable analyses.

### Trade-offs
While stratified random sampling ensures proportional representation and enhances the precision of survey estimates, it is not without challenges. One notable trade-off is the complexity involved in defining and managing multiple strata, particularly when the strata are based on multiple dimensions such as application type, planning district, and applicant role. This complexity increases the time and resources required for sample design and execution. For instance, ensuring proportional representation across strata like **Scarborough developers** or **North York consultants** may necessitate oversampling in smaller groups, leading to additional effort in recruitment and logistical coordination.

Another trade-off lies in the potential for overstratification, which can result in small sample sizes within certain strata. If some strata, such as **Scarborough Consent applications**, have very few members, it may be difficult to draw statistically meaningful conclusions. This could necessitate adjustments, such as combining smaller strata or applying post-stratification weighting, which could introduce bias or reduce interpretability. Additionally, the method assumes that the characteristics used to define strata are adequately known and relevant, which may not account for unobserved variables that influence the outcomes, such as the socio-political environment or project complexity. Despite these challenges, the benefits of stratified random sampling in terms of improved accuracy and subgroup analysis make it a robust choice for this study.


## Data Validation
Survey responses would be validated through cross-referencing with the cleaned dataset. For instance:

Matching survey-reported outcomes with recorded decisions.
Verifying consistency between applicant-reported application details and dataset attributes (e.g., application type, planning district).
To ensure representativeness, response rates would be monitored, and additional recruitment efforts would target underrepresented groups or districts.



## Survey

This survey will be conducted using Google Forms, which is an effective platform for data
collection. The survey can be accessed by the link, [Google Form Survey](https://forms.gle/SVyeccgCSsjhQzWX7).

### Survey Structure

**Title:**

Understanding Urban Planning Decisions

**Introduction:**

I appreciate your participation in this survey, which seeks to better understand the factors influencing urban planning decisions and application outcomes in Toronto. Your responses are pivotal for enhancing the research and contributing to perceptions that could inform future urban planning processes.

**Please note:**

- Your answers will be treated with complete confidentiality.
- Participation in this survey is voluntary.
- You are encouraged to provide honest and thoughtful responses.
- The survey is estimated to take about 5 minutes to complete.
- If you have any questions or concerns, feel free to reach out to me at [anjojoo.xu@mail.utoronto.ca](anjojoo.xu@mail.utoronto.ca) (Angel Xu).

Thank you for your significant contribution! As a token of our appreciation, each participant will receive $5 upon completion of the survey.

**Section 1: Application Details**

What type of application did you submit?

- MV (Minor Variance)

- CO (Consent)

- Prefer not to say

Which planning district was your application associated with?

- North York

- Scarborough

- Etobicoke York

- Toronto East York

- Prefer not to say

Which year did you submit your application?

- 2016

- 2017

- 2018

- 2019

- 2020

- 2021

- 2022

- 2023

- 2024

- Other (please specify)

What was the outcome of your application?

- Approved

- Refused

- Prefer not to say

- Others (please specify)

**Section 2: Applicant Background**

What role best describes your involvement in the application process?

- Property Owner

- Developer

- Consultant

- Prefer not to say

- Others (please specify)

How many years of experience do you have in urban planning or related fields?

- <1 year

- 1–5 years

- 5–10 years

- >10 years

- Prefer not to say

**Section 3: Process and Challenges**

What was the primary purpose of your application?

- Residential Adjustment

- Commercial Development

- Mixed-Use Development

- Prefer not to say

- Others (please specify)

What challenges did you encounter during the application process?

- Zoning Compliance

- Documentation Requirements

- Public Objections

- Prefer not to say

- Others (please specify)

**Section 4: Influences on Decisions**

Do you believe community feedback impacted the outcome of your application?

- Yes

- No

Were there any external factors (e.g., economic conditions, policy changes) that influenced the decision?

- Yes

- No

Do you have any further comments or awareness about the factors that might affect the application decision?

[answer box]

**Section 5: Feedback and Improvements**

What improvements would you recommend for the application process?

- Streamlining Documentation

- Clearer Guidelines

- Enhanced Community Engagement

- Others (please specify)

Do you have any further comments or awareness about the application process?

d[answer box]

**End Message:**
Thank You for Completing the Survey!

We sincerely appreciate your time and thoughtful responses. Your participation is essential in helping us gain a deeper understanding of the factors influencing urban planning decisions in Toronto. Your awareness will contribute to research aimed at improving zoning application processes and understanding decision dynamics.

If you have any questions or would like to learn more about this study, please don’t hesitate to contact our research team at [anjojoo.xu@mail.utoronto.ca](anjojoo.xu@mail.utoronto.ca) (Angel Xu).

As a token of our gratitude, each participant will receive a $5 reward shortly after completing the survey. Thank you again for your significant contribution!


## Surevey Design Consideration

When designing the survey, several key factors were considered to ensure representativeness, clarity, and relevance to the study's objectives. The survey targets individuals involved in Toronto’s urban planning processes, including property owners, developers, and consultants.

Question phrasing was tailored to align with terminology familiar to the target respondents, minimizing ambiguity. Efforts were also made to limit the survey's length to encourage participation while ensuring sufficient data for meaningful analysis. A balance was struck between closed-ended questions, which facilitate quantitative analysis, and open-ended questions, which capture intricate qualitative findings. Additionally, the survey design accounted for ethical considerations, such as maintaining confidentiality and emphasizing voluntary participation.


## Strength

The survey design has several strengths. Stratified random sampling ensures that the results are representative of the population, reducing sampling bias. By aligning strata with key demographic and process variables, the survey facilitates detailed subgroup analysis, enhancing the depth of discovery. The inclusion of both quantitative and qualitative questions allows for an overall understanding of the factors influencing urban planning decisions. Closed-ended questions enable statistical analysis, while open-ended responses provide richer context and identify factors not captured in the observational dataset.

The survey also addresses gaps in the cleaned dataset, such as perceptions of community feedback, challenges during the application process, and external influences on decisions. They complement the quantitative data, offering a more holistic view of the decision-making process.


## Weakness

Despite its strengths, the survey has some limitations. Stratified random sampling requires precise knowledge of the population's composition, which may not always be accurate, particularly for less-documented strata. Smaller strata, such as applications from certain districts or less common applicant roles, may result in small sample sizes, limiting statistical power. Additionally, reliance on self-reported data introduces the potential for response bias, as participants may overstate or understate certain factors, particularly regarding the impact of community feedback or external influences.

The survey's limited length, while improving completion rates, may constrain the depth of responses, especially for complex topics. Furthermore, the survey results are context-specific, reflecting Toronto’s unique regulatory framework and urban planning dynamics, which may limit the generalizability of findings to other cities or contexts. Despite these challenges, the survey is a useful tool for supplementing the dataset and addressing research objectives.


\newpage


# References


