---
title: "Understanding Factors Contributing to Application Approval in Urban Planning Decisions (2016-2024)"
subtitle: "Analysis using data from Toronto’s Committee of Adjustment applications using Bayesian Logistic Regression"
author: Angel Xu
thanks: "Code and data are available at: [https://github.com/Anjojoo/Committee-of-Adjustment-Applications](https://github.com/Anjojoo/Committee-of-Adjustment-Applications)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(opendatatoronto)
library(modelsummary)
library(knitr)

analysis_data <- read_csv(here::here("data/02-analysis_data/analysis_data.csv"))
```


# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....


## Estimand



# Data {#sec-data}

## Overview

Our data [@committee_application] is extracted from opendatatoronto [@opendatatoronto]. This dataset focuses on applications submitted to the City of Toronto's Committee of Adjustment, a governing body responsible for reviewing minor variance and consent applications related to land use and development. These applications are submitted by property owners and developers seeking permission to deviate from existing zoning regulations or to subdivide land. The Committee’s decisions—whether to approve or refuse an application—have significant implications for urban development, community planning, and city growth.

The Committee of Adjustment plays a key role in Toronto’s urban planning ecosystem. It ensures that deviations from zoning bylaws align with the city’s broader development objectives, maintaining a balance between flexibility for property owners and adherence to long-term planning goals. The decisions made by the committee are influenced by various factors, including the type of application, geographic considerations (e.g. planning districts), and the timing of submission. Understanding these decisions provides insight into urban planning dynamics and the regulatory challenges faced by a growing city like Toronto.

The analysis presented in this paper were conducted using R programming language [@citeR]. The `tidyverse` packages [@citetidyverse], `dplyr` package [@citedplyr], and `arrow` package [@citearrow] were used in the process of data simulation, testing beforehand. After the original raw data was downloaded by using `tidyverse` package [@citetidyverse], and `dplyr` package [@citedplyr], data cleaning process was done by using `tidyverse` package [@citetidyverse], `dplyr` package [@citedplyr], and `arrow` package [@citearrow]. The code style is corrected by `here` package [@citehere], `lintr` package [@citelintr], and `styler` package [@citestyler]. Then, models were constructed using `tidyverse` package [@citetidyverse], and `rstanarm` [@citerstanarm] package. Graphs were made with `ggplot2` package [@citeggplot]. Tables were constructed with `knitr` package [@citeknitr]. The model results are then presented by `modelsummary` [@citemodelsummary] package.

Following @tellingstories, this paper uses Bayesian Logistic Model to explore factors that affect the application results.

Although several similar datasets with overlapping themes were considered but ultimately not used due to limitations in scope, structure, or relevance. For instance, the Toronto Application Information Centre Dataset provides information on broader planning applications like rezoning requests and site plan approvals, but its complexity and inclusion of unrelated application types make it unsuitable for isolating patterns related to minor variances and consents. The Ontario Municipal Board (OMB) Decisions Dataset includes appeal outcomes, but its focus on contested cases introduces bias and omits the routine applications central to this study.

Consequently, focusing on the Committee of Adjustment Applications dataset [@committee_application] stands out for its granularity and relevance, enabling a focused analysis of approval trends and their influencing factors, which directly aligns with the study's goals.


## Measurement
	
The dataset captures information on applications submitted to the City of Toronto’s Committee of Adjustment, providing a structured record of decisions made on zoning variances and consents. The dataset’s structure results from Toronto’s well-defined application process. When property owners or developers submit applications to the Committee of Adjustment, they provide detailed information about their project, including its location, purpose, and the specific variances or consents requested. These details are reviewed by committee staff and entered into a digital database, ensuring consistency and standardization.

Applications to the Committee of Adjustment are typically submitted by property owners, developers, or their authorized agents (e.g., architects or planners). Eligibility to submit an application requires ownership or legal rights to the property in question. For some application types, such as consents, additional prerequisites include demonstrating compliance with existing zoning bylaws or providing documentation showing that the proposed subdivision aligns with city planning objectives. Minor variance applications, on the other hand, require applicants to show that the requested adjustments are “minor” in nature, do not conflict with broader zoning intentions, and maintain compatibility with the surrounding area. As a result, individuals submitting these applications are often professionals with expertise in urban planning, real estate, or development, or property owners working in consultation with such professionals.

The data collection process begins with property owners or developers submitting applications through a centralized system. Each application includes essential details, which are systematically verified and recorded by administrative staff. Following public hearings, committee decisions (approval or refusal) are added to the database, completing the data entry process. The dataset is then maintained and periodically published by the City of Toronto, ensuring it remains accessible and accurate for public and analytical use.

The dataset thus provides a structured lens through which to examine urban planning decisions. By distilling real-world phenomena—such as zoning adjustments and land use approvals—into discrete variables, the dataset enables systematic analysis of trends and relationships within Toronto’s regulatory framework. This structured approach ensures that the dataset is both practical for analysis and representative of the nuanced processes underlying urban development.


## Data Cleaning

To ensure the dataset was suitable for analysis, several high-level cleaning steps were performed. First, unused decision outcomes were filtered out, retaining only applications that were explicitly approved or refused. The `decision` variable was then converted into a binary format, with `1` representing approvals and `0` representing refusals, simplifying its use in modeling.

A new variable, `year`, was constructed by extracting the year from the `in_date` field. This allowed for a clearer examination of temporal trends while maintaining the granularity of the original data. Applications from very early years with minimal counts were excluded to avoid bias and ensure a representative analysis of contemporary decision-making trends.

Additionally, key variables are selected out in cleaned dataset for convenience. More details will be explored in appendix.


## Features

The dataset provides details of applications submitted to the Committee of Adjustment, focusing on key variables:

- Decision: Indicates whether an application was approved or refused.
- Application Type: Categorizes the application as either a minor variance or a consent.
- Year: The year when the application was submitted.
- Planning District: The geographic area within Toronto where the application originated.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-preview
#| tbl-cap: "Preview of Key Variables"

# Show first six rows of the cleaned dataset
analysis_data |>
  head() |>
  kable(booktabs = TRUE, align = "c")
```

The first six rows of the cleaned dataset, displayed in @tbl-preview, offer a clear preview of these key variables.

These variables allow for an in-depth analysis of the factors influencing application decision results and provide a quantitative basis for evaluating trends in urban planning decisions. Specific and further discussion about these variables are included in @sec-data-outcome and @sec-data-predictor.


## Outcome variables {#sec-data-outcome}

The outcome variable, decision, captures whether an application submitted to the Committee of Adjustment was approved (represented as 1) or refused (represented as 0).

```{r}
#| label: fig-decision
#| fig-cap: Distribution of Application Decisions
#| echo: false
#| warning: false
#| message: false

#### Workspace Setup####
library(ggplot2)

#### Plot the distribution of `decision` ####
ggplot(analysis_data, aes(x = factor(decision))) +
  geom_bar(fill = "lightblue", color = "black") +
  geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5) +
  labs(
    x = "Decision (0 = Refused, 1 = Approved)",
    y = "Count"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text = element_text(size = 12)
  )

```

@fig-decision illustrates the distribution of decision outcomes. Out of the total applications, 1,207 (66.5%) were approved, while 607 (33.5%) were refused. This demonstrates that the majority of applications submitted to the Committee of Adjustment are approved, suggesting that most requests align with zoning regulations or are deemed acceptable following the committee's review process.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-decision
#| tbl-cap: "Summary Statistics of Decisions"

#### Generate summary statistics for `decision` ####
decision_summary <- analysis_data %>%
  group_by(decision) %>%
  summarize(
    Percentage = paste0(round((n() / nrow(analysis_data)) * 100, 1), "%") # Add '%' symbol
  ) %>%
  mutate(Decision = ifelse(decision == 1, "Approved (1)", "Refused (0)")) %>%
  select(Decision, Percentage)

#### Create a kable table ####
decision_summary %>%
  kable(
    format = "html", 
    col.names = c("Decision", "Percentage")
  )
```

@tbl-decision provides a clear picture of the approval and refusal rates within the dataset, highlighting a relatively high likelihood of approval for submitted applications.


## Predictor variables {#sec-data-predictor}

### Application type

The application type variable categorizes each application submitted to the Committee of Adjustment into two types:

Consent (CO): Requests related to the subdivision of land into separate parcels, often for new developments or property sales.

Minor Variance (MV): Applications seeking small adjustments to zoning regulations, such as building setbacks, height limits, or lot coverage.

These categories represent distinct regulatory processes, with Consents generally requiring more extensive evaluation compared to Minor Variances due to their implications on land use.

```{r}
#| label: fig-application-types
#| fig-cap: Distribution of Application Types
#| echo: false
#| warning: false
#| message: false

#### Plot the distribution of `application_type` ####
ggplot(analysis_data, aes(x = factor(application_type))) +
  geom_bar(fill = "lightgreen", color = "black") +
  geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5) +
  labs(
    x = "Application Type",
    y = "Count"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text = element_text(size = 12)
  )


```

@fig-application-types presents the distribution of applications by type. Minor Variances account for the majority of applications which reach to 1371 (75.6%), reflecting the routine nature of these requests in urban development. In contrast, Consents are less frequent which only have 443 counts (24.4%), likely due to their more specific requirements and potential complexity.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-application-type
#| tbl-cap: "Summary Statistics of Application Types"

#### Summary Statistics for Application Type ####
application_summary <- analysis_data %>%
  group_by(application_type) %>%
  summarize(
    Percentage = paste0(round((n() / nrow(analysis_data)) * 100, 1), "%") # Add %
  ) %>%
  mutate(Application_Type = ifelse(application_type == "MV", "Minor Variance (MV)", "Consent (CO)")) %>%
  select(Application_Type, Percentage)

#### Create a kable table ####
application_summary %>%
  kable(
    format = "html", 
    col.names = c("Application Type", "Percentage")
  )
```

@tbl-application-type emphasize the dominance of Minor Variances in the dataset, providing context for their role in urban development.

The relationship between application_type and the outcome variable decision will be explored further to determine if approval rates differ between Minor Variances and Consents. Preliminary trends suggest that Minor Variances may have higher approval rates due to their less complex nature. Additional analyses may examine whether these patterns vary by planning district or year.


### Year

The year variable represents the year of submission for each application in the dataset. It provides insight into temporal trends in applications submitted to the Committee of Adjustment. This variable is instrumental in identifying changes in the volume of applications over time, which may reflect policy shifts, urban development trends, or external factors like economic conditions.

```{r}
#| label: fig-year
#| fig-cap: Distribution of Applications Years
#| echo: false
#| warning: false
#| message: false

#### Plot the distribution of `year` ####
ggplot(analysis_data, aes(x = factor(year))) +
  geom_bar(fill = "skyblue", color = "black") +
  geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5) +
  labs(
    x = "Year",
    y = "Count"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text = element_text(size = 12)
  )


```

@fig-year clarifies the distribution of applications from 2016 to 2024, with notable fluctuations in annual counts. Fewer applications were submitted during 2016-2019, with counts declining steadily from 198 applications in 2016 to a low of 93 in 2019. This period may reflect a stabilization phase or lower activity in urban development processes. Afterwards, application counts increased significantly, peaking in 2023 with 378 applications, followed by a slight decline to 249 in 2024. The rise in 2023 may be due to heightened development activity or easing of restrictions from prior external events, such as the COVID-19 pandemic.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-year
#| tbl-cap: "Summary Statistics of Years"

#### Summary Statistics for Year ####
year_summary <- analysis_data %>%
  group_by(year) %>%
  summarize(
    Percentage = paste0(round((n() / nrow(analysis_data)) * 100, 1), "%")
  ) %>%
  arrange(year)

#### Create a kable table ####
year_summary %>%
  kable(
    format = "html", 
    col.names = c("Years", "Percentage")
  )
```

@tbl-year states how each year contributes to the total volume of applications.

The year variable is likely related to the decision outcome and application type. As approval rates may have varied over time due to changing city planning policies or committee priorities. Besides, temporal trends may reveal shifts in the proportion of Minor Variances (MV) versus Consents (CO), reflecting evolving development demands.


### Planning District

The planning district variable identifies the geographic district within Toronto where an application was submitted. The city is divided into four planning districts, each with its own development characteristics and zoning regulations. These districts are crucial for understanding spatial trends in application submissions and outcomes, as local policies and priorities can influence decision-making processes.

```{r}
#| label: fig-district
#| fig-cap: Distribution of Planning District
#| echo: false
#| warning: false
#| message: false

#### Plot the distribution of `planning_district` ####
ggplot(analysis_data, aes(x = factor(planning_district))) +
  geom_bar(fill = "coral", color = "black") +
  geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5) +
  labs(
    x = "Planning District",
    y = "Count"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1) # Rotate district labels for readability
  )

```

@fig-district displays the distribution of applications across four planning districts. We can observe that North York has the highest number of applications, accounting for a significant proportion of the dataset. This could reflect the area's high density of development projects or active property owners seeking zoning adjustments. Scarborough has the fewest applications, possibly due to fewer development activities or stricter zoning compliance. Etobicoke York and Toronto East York have moderate numbers of applications, reflecting their roles as active but less prominent districts compared to North York.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-district
#| tbl-cap: "Summary Statistics of Planning Districts"

#### Summary Statistics for Planning District ####
district_summary <- analysis_data %>%
  group_by(planning_district) %>%
  summarize(
    Percentage = paste0(round((n() / nrow(analysis_data)) * 100, 1), "%")
  )

#### Create a kable table ####
district_summary %>%
  kable(
    format = "html", 
    col.names = c("Planning Districts", "Percentage")
  )
```

@tbl-district provide a view of how applications are distributed spatially across the city.

The planning_district variable may also interacts with application type and decision. Approval rates may vary by district, reflecting differences in local policies or development dynamics. The proportion of Minor Variances (MV) versus Consents (CO) may differ across districts, indicating distinct development priorities or zoning challenges.


# Model {#sec-model}

In this paper, a Bayesian logistic model will be utilized to understand how factors such as application type, submission year, and planning district influence the decisions of the application committee. This model estimates the probability of an application being approved (P(Approval)) based on the given predictors.

The goal of this modeling strategy is twofold: (1) to estimate how each predictor affects the likelihood of approval, and (2) to quantify the uncertainty associated with these estimates. This approach is well-suited for incorporating prior knowledge while addressing the hierarchical nature of the predictors, such as geographic regions.

We run the model in R [@citeR] using the `rstanarm` package of @citerstanarm. `rstanarm`@citerstanarm is used to set up the model.

Here we briefly describe the Bayesian analysis model used to investigate, and include justification for model and the variables, as well as discuss underlying assumptions, potential limitations, and evidence of model validation and checking.

Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

In the Bayesian logistic regression model, the response variable $y$ follows a Bernoulli distribution, reflecting its binary nature. Coefficients $\beta_k$ (where k=0,1,2,3) of every predictor variables follow a Normal distribution. Specifically:

\begin{align} 
y_i|p_i &\sim \mbox{Bern}(p_i) \\
\beta_0 &\sim \mbox{Normal}(0, 2.5) \\
\beta_1 &\sim \mbox{Normal}(0, 2.5) \\
\beta_2 &\sim \mbox{Normal}(0, 2.5) \\
\beta_3 &\sim \mbox{Normal}(0, 2.5)
\end{align}

Combining all the components, the complete model can be expressed as:

\begin{equation}
\log\left(\frac{p_i}{1 - p_i}\right) = \beta_0 + \beta_1 \times \text{application type} + \beta_2 \times \text{year} + \beta_3 \times \text{planning district}
\end{equation}

- $p_i$: the probability for the binary outcome variable to be 1 (1 = approval, 0 = refusal).
- $\beta_0$: Intercept, representing the baseline log-odds of approval for the reference levels of the predictors.
- $\beta_1$: Coefficients for application type, dummy-coded with CO as the reference category.
- $\beta_2$: Coefficient for year, measured as the year of application to capture temporal trends.
- $\beta_3$: Coefficients for planning district, dummy-coded with North York as the reference category.

In the above Bayesian logistic regression model, the coefficients $\beta = {\beta_0, \beta_1, \beta_2, \beta_3}$ are treated as random variables, each following a specified prior distribution. These priors represent our initial beliefs about the plausible values of the coefficients before observing the data. In this model, each $\beta_k$ (where k=0,1,2,3) is assigned a normal distribution, with a zero mean and 2.5 standard deviation. The choice of these parameters reflects a weakly informative prior, centered around zero to express no strong prior belief about the direction or magnitude of the effects, while allowing for reasonable variability in the coefficient estimates.

The normal distribution is particularly suitable for these priors because it reflects a belief that most effects are likely to be small or moderate, centered around zero, while allowing for deviations in either direction. The standard deviation of 2.5 is a practical choice for weakly informative priors, offering a balance between constraining the parameters and allowing the data to influence the estimates. This ensures that the model avoids overfitting, particularly when data is sparse or multicollinearity exists among predictors.

After observing the data, the posterior distributions of $\beta$ are obtained by combining these priors with the likelihood of the observed outcomes. The resulting posterior distributions provide updated beliefs about the coefficients, incorporating both prior knowledge and evidence from the data. This approach allows for robust inference, offering a clear quantification of parameter uncertainty and supporting more nuanced interpretations of the predictors' effects.


## Model justification

The Bayesian logistic regression model is an appropriate choice for analyzing how application type, submission date, and planning district influence the likelihood of application approval. This choice is driven by the binary nature of the response variable, the model's ability to incorporate prior knowledge, and its probabilistic framework, which quantifies uncertainty more effectively than frequentist alternatives. Logistic regression naturally constrains predicted probabilities to the [0,1] interval, ensuring interpretability as likelihoods of approval, while the Bayesian approach enhances flexibility and provides richer insights through posterior distributions.

Compared to traditional generalized linear models (GLM), the Bayesian approach allows for the inclusion of prior beliefs through weakly informative priors ($N(0, 2.5)$) for all coefficients. These priors help stabilize the model, particularly in cases where data is sparse or multicollinear, without overwhelming the contribution of the observed data. Additionally, Bayesian methods yield full posterior distributions rather than single-point estimates, allowing for a clearer understanding of parameter uncertainty and a better capacity to incorporate uncertainty into decision-making processes. These advantages make the Bayesian logistic regression model preferable to a standard GLM, which provides point estimates and relies on asymptotic approximations for inference.

The model also stands out against simpler approaches, such as simple linear regression (SLR). While SLR might be used for binary outcomes in certain contexts, it is theoretically inappropriate because it does not constrain predictions to the [0,1] interval. This can result in nonsensical predicted probabilities outside this range. Moreover, SLR assumes a linear relationship between predictors and the response variable, which is unsuitable for binary outcomes. The logit transformation in logistic regression, by contrast, ensures a proper probabilistic framework while preserving interpretability in terms of log-odds.

The predictors included in the model further justify the choice of Bayesian logistic regression. Application type captures fundamental differences in how various categories of applications, such as minor variances and consents, might affect approval outcomes. Submission date is treated as a continuous variable, reflecting temporal trends without arbitrary grouping, while planning district accounts for geographic variability through categorical indicators. These predictors are naturally suited to a logistic framework, and the Bayesian approach accommodates any inherent variability in their effects.

In summary, Bayesian logistic regression provides a robust, clarified, and flexible framework for analyzing the factors influencing application decisions. Its advantages over GLM and SLR include the ability to incorporate prior information, quantify uncertainty, and handle the non-linear nature of the binary response variable. By balancing methodological rigor with practical transparency, this model ensures that the analysis remains both statistically sound and actionable for stakeholders.


## Model Assumption

This Bayesian model relies on several assumptions that ensure the validity of its predictions and the transparency of its coefficients. While these assumptions are generally less restrictive than those for simpler models like linear regression, they remain critical to the robustness of the results. The key assumptions are listed below:

1. Binary Response Variable
The model assumes that the response variable ($y$) is binary, taking values of either 1 (approval) or 0 (refused). This assumption aligns with the nature of the data, as application decisions are dichotomous outcomes. Any deviations from binary coding would invalidate the logistic framework and require alternative modeling approaches.

2. Independence of Observations:
The model assumes that all observations are independent of one another. This is reasonable for application data, as each decision is typically made independently by the committee. However, if clustering or dependence exists (e.g., decisions within the same planning district are correlated), the model may need to incorporate hierarchical or random effects to address these dependencies.

3. No Perfect Multicollinearity
Logistic regression assumes that the predictors are not perfectly correlated, as this would prevent the model from estimating unique coefficients. For example, if a predictor is a linear combination of other predictors, the model would fail to converge. In this analysis, categorical variables of application type and planning district are appropriately encoded to avoid such issues.

4. Proper Model Specification
The model assumes that all relevant predictors are included and correctly specified. Omitting important variables or including irrelevant ones could lead to biased estimates or reduced transparency. For example, excluding interaction terms when they are theoretically justified might result in incomplete understanding of the predictors' effects.


## Potential Limitation and Addressing Violation

Violations of the above assumptions can impact this model’s validity while severl solution are listed below:

1. Non-linearity:
Adding polynomial terms or splines could address non-linear relationships if diagnostic checks suggest deviations.

2. Dependence:
If observations are not independent (e.g. decisions clustered by region), hierarchical models or random effects may be introduced.

3. Multicollinearity:
Variance inflation factors or correlation matrices can help identify multicollinearity issues, which can be resolved by removing or combining correlated predictors.

By adhering to these assumptions and addressing potential violations, the Bayesian logistic regression model provides a robust and effective framework for analyzing the factors influencing application outcomes.


## Model Validation

To ensure the robustness and reliability of the Bayesian logistic regression model, a series of validation and diagnostic steps were conducted. Detailed plots and results, including posterior predictive checks (PPC), posterior vs. prior comparisons, and convergence diagnostics, are provided in the appendix for further examination. Below, the focus is on other key validation methods:

1. **Out-of-Sample Testing**

The dataset was split into a training set (80%) and a test set (20%) to evaluate the model's predictive performance on unseen data. The model was trained on the training set, and predictions were made on the test set. Classification accuracy was calculated as the proportion of correctly classified outcomes in the test set. This approach assesses the model's generalizability.

2. Confusion Metrix

3. Sensitivity Analysis
The sensitivity of the model was assessed by varying the priors for the coefficients to examine whether the results were robust to different prior specifications. The predictions remained stable across different prior choices, indicating that the model is not overly influenced by prior assumptions.

4. Predictive Power (AUC-ROC)
The Area Under the Receiver Operating Characteristic Curve (AUC-ROC) was computed to evaluate the model's ability to discriminate between approved and refused applications. A high AUC-ROC value (>0.8) confirmed the model's strong discriminatory performance.


# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

model <-
  readRDS(file = here::here("models/first_model.rds"))
```


```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Model results of Application Approval Probability"
#| warning: false

model <- model

modelsummary::modelsummary(
  list(
    "Model" = model
  ),
  statistic = "mad",
  fmt = 2
)
```

The result highlights how the predictors influence the likelihood of application approval while controlling for other variables. The coefficients, presented as log-odds, provide insights into both the direction and magnitude of each predictor’s impact on the approval decision.

The intercept estimate of -0.06 represents the baseline log-odds of approval when all predictors are at their reference levels. This corresponds to a baseline probability close to 0.5, indicating nearly equal odds of approval or refusal in the absence of other influencing factors. This serves as a neutral starting point for understanding how the predictors shift the likelihood of approval.

The variable application_typeMV, with a coefficient of -0.20, suggests that applications for minor variances (MV) are less likely to be approved compared to consents (CO), which act as the reference category. In terms of odds, the transition from a consent to a minor variance reduces the odds of approval by approximately 18% ($e^{-0.20}\approx 0.82$). This finding aligns with expectations, as minor variances may face stricter scrutiny due to their potentially greater impact on local zoning adjustments.

The year variables reveal notable temporal trends in approval likelihood, using 2016 as the reference year. Applications submitted in 2017 had significantly higher odds of approval, with a 109% increase in odds compared to 2016 ($e^{0.74}\approx 2.09$). This upward trend continued into 2018, which saw the highest approval odds, with a 161% increase over 2016 ($e^{0.96}\approx 2.61$). In 2019, the odds of approval remained positive but were less pronounced, with a 25% increase over 2016 ($e^{0.22}\approx 1.25$). By 2020, the odds rose again, with a 75% increase compared to the baseline year ($e^{0.56}\approx 1.75$). These results suggest that approval rates have generally improved over time, potentially reflecting shifts in policy, procedural efficiency, or external factors affecting decision-making.

The planning district coefficients provide insight into geographic variability in approval rates, highlighting differences in decision-making across Toronto’s planning regions. North York leads in both application volume and approval odds, reflecting its role as a development hub. Scarborough faces lower approval odds, suggesting distinct planning challenges or fewer adjustments being approved. These geographic differences likely reflect localized development pressures, zoning considerations, or district-specific challenges that influence decision-making.

In summary, the model reveals key patterns in how application type and submission year influence the likelihood of approval. Minor variance applications face slightly lower odds of approval compared to consents, while temporal trends indicate an overall increase in approval rates from 2016 to 2020. These findings provide a foundation for understanding the dynamics of approval decisions and highlight areas for further exploration, such as geographic variability or interactions between predictors.


```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

# #### Extract coefficients and statistics ####
# # Extract summary of the model
# model_summary <- summary(model)$coefficients
# 
# # Convert to a data frame
# model_summary_df <- as.data.frame(model_summary)
# 
# # Add row names (predictor names) as a column
# model_summary_df <- model_summary_df %>%
#   rownames_to_column(var = "term") %>% # Convert row names to a column
#   rename(
#     Estimate = Estimate, # Mean estimate (log-odds)
#     StdError = `Std. Error` # Rename standard error for clarity
#   ) %>%
#   mutate(
#     conf.low = Estimate - 1.96 * StdError, # Confidence interval lower bound
#     conf.high = Estimate + 1.96 * StdError # Confidence interval upper bound
#   ) %>%
#   filter(term != "(Intercept)") # Exclude intercept for clarity
# 
# #### Create the coefficient plot ####
# ggplot(model_summary_df, aes(x = reorder(term, Estimate), y = Estimate)) +
#   geom_point(size = 3, color = "blue") +
#   geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2, color = "black") +
#   coord_flip() +
#   labs(
#     title = "Estimated Coefficients with 95% Confidence Intervals",
#     x = "Predictor",
#     y = "Coefficient (Log-Odds)"
#   ) +
#   theme_minimal(base_size = 14) +
#   theme(plot.title = element_text(hjust = 0.5))
```


# Discussion

## Overview

This paper investigates the factors influencing application approvals submitted to the City of Toronto's Committee of Adjustment, using a Bayesian logistic regression model. By analyzing predictors such as application type, submission year, and planning district, the study provides insights into the dynamics of urban planning decisions. The model captures temporal trends, spatial variability, and procedural differences, offering a structured understanding of approval outcomes. Visualizations, including coefficient plots and effect plots, complement the analysis, helping to interpret the relationships between predictors and approval likelihood.

## Temporal Trends in Approval Rates

One key finding is the temporal trend in approval rates. The analysis reveals that approval odds have increased steadily over time, peaking in 2018. This trend may reflect evolving planning policies, greater efficiency in committee processes, or a shift in zoning priorities. The data suggests that the Committee of Adjustment has become more permissive in granting approvals, which could indicate a growing alignment between applications and city planning objectives. This result highlights how administrative processes adapt over time to urban development needs.

## Geographic Disparities in Approval Decisions

Spatial variability plays a significant role in application approvals. The findings show that North York consistently exhibits the highest approval rates, likely due to its prominence as a development hub with infrastructure supporting large-scale projects. Conversely, Scarborough has the lowest odds of approval, suggesting stricter zoning enforcement or less alignment with development objectives in this area. This geographic disparity underscores the influence of local contexts and priorities on urban planning decisions, revealing how different districts balance growth and zoning compliance.

## Weaknesses

While this paper provides insights into the factors influencing application approvals, there exists several limitations. These weaknesses cover data-related issues, methodological constraints, and broader contextual considerations.

1. **Data Limitations**
The analysis relies solely on the dataset provided by the City of Toronto's Committee of Adjustment, which, while complete in its coverage of applications, lacks certain critical variables. Key contextual factors, such as community objections, project complexity, or the presence of political or economic pressures, are not captured. For instance, the dataset does not provide information about why certain applications are refused or approved beyond the recorded decision, limiting the ability to analyze qualitative or situational influences.

2. **Methodological Constraints**
The Bayesian logistic regression model assumes that the relationships between predictors and the outcome variable are additive and linear on the log-odds scale. This assumption may oversimplify real-world interactions between variables, such as how specific planning districts may interact with application types or temporal trends. Furthermore, the model does not fully account for potential multicollinearity among predictors, which could distort the estimated coefficients. While priors were carefully chosen, their influence on the results might vary with a different prior specification, introducing some degree of subjectivity into the analysis.

3. **Simplified Representation of Approval Dynamics**
The approval process involves a combination of bureaucratic procedures, stakeholder negotiations, and technical considerations that are not fully captured in this analysis. For example, public hearings, lobbying efforts, and input from local communities likely play a significant role in shaping decisions but are absent from the dataset. This simplification means that the model captures only part of the story, potentially overlooking nuanced dynamics in urban planning and governance.

4. **Geographic and Temporal Generalizability**
The analysis focuses exclusively on the City of Toronto, meaning the findings are context-specific and may not generalize to other municipalities with different urban planning frameworks, policies, or demographic pressures. Temporal trends in approval rates, for example, could be influenced by unique local events or policy changes that are not representative of broader patterns. Similarly, the observed geographic variability in approval rates might reflect Toronto-specific zoning challenges rather than universal principles.


## Nest Steps

Building on the findings and addressing the limitations of this paper, there are several avenues for future research and analysis that could provide a deeper understanding of the factors influencing application approvals in urban planning contexts.

One critical next step is to expand the dataset by incorporating additional variables that capture contextual and qualitative factors influencing decisions. Data on community feedback and objections during public hearings is a good choice since it could provide insights into how local resistance or support impacts approval likelihood. Information on project complexity, such as the scale, type, and potential impact of proposals, could reveal patterns in decision-making. Besides, access to committee meeting notes or further exploration in meeting minutes would help clarify the reasoning behind specific approvals or refusals. Furthermore, integrating economic and political context, such as local economic indicators or changes in political leadership, would offer a broader understanding of approval trends.

The current model assumes additive relationships between predictors and approval likelihood, which may oversimplify real-world dynamics. Future research could explore nonlinear relationships, such as whether certain predictors have diminishing or exponential effects on approval rates. Interaction effects between predictors, such as the interplay between planning districts and application types, could also provide more nuanced insights. For instance, minor variances may be treated differently in densely populated urban areas compared to suburban districts.

Extending this analysis to other municipalities or regions would help determine whether the observed trends in Toronto are unique or indicative of broader urban planning practices. Cross-regional comparisons could identify common principles across jurisdictions, highlight local deviations driven by distinct policies or demographics, and establish benchmarks for understanding how Toronto’s process aligns with other cities. Such studies could enhance the generalizability of findings and provide practical lessons for urban planners in different contexts.

Despite to future improvements for addressing limitations, further exploration can be continued based on the current result. The temporal trends identified in this paper suggest shifts in approval rates over time, but the reasons behind these changes remain unexplored. Future work could examine specific policy changes or regulatory updates to understand their impact on approval trends. Additionally, external events such as economic downturns, housing crises, or infrastructure investments could be analyzed for their influence on application volumes and decisions. A difference-in-differences approach could also help isolate the effects of significant policy interventions, providing a clearer picture of causal relationships.

Given the importance of geographic variability in approval rates, future research could adopt spatial analysis techniques. Spatial regression models could account for spatial autocorrelation and clustering effects in planning districts, while network analysis could study relationships between districts, such as spillover effects of development activity. Additionally, analyzing proximity to key infrastructure, such as transit hubs or commercial centers, could provide insights into spatial patterns of decision-making.

Finally, the findings from this paper could inform the development of predictive tools to assist urban planners and developers. These tools could provide probabilistic forecasts of approval likelihood based on project attributes and contextual factors. Additionally, they could help committees identify systemic biases or inefficiencies in their decision-making processes and aid policymakers in designing more equitable and transparent approval frameworks.

In summary, future research should prioritize richer data integration, explore more sophisticated modeling techniques, and broaden the scope of analysis to other regions and temporal contexts. These steps would not only enhance academic understanding of urban planning decisions but also provide actionable insights for policymakers, developers, and urban planners working toward effective and equitable processes.

\newpage

\appendix

# Appendix {-}


# Additional data cleaning details

The dataset underwent a structured cleaning process to ensure its suitability for analysis, focusing on preparing the data while minimizing bias and enhancing interpretability. Below is a detailed description of the key cleaning steps:

1. **Filtering Unused Decision Outcomes**

The dataset originally included a range of decision outcomes beyond approvals and refusals, such as applications that were deferred or withdrawn. These were excluded to focus solely on cases where the Committee of Adjustment made a definitive decision. This exclusion is done by filtering decisions with "approve", "approval", and "refused" words in it while conditionally approved are all default as approval to enlarge the data size. This ensured a binary structure for the decision variable, aligning with the study’s objectives.

2. **Conversion of decision to Binary Format**

The decision variable was converted into a binary format for consistency and ease of analysis:

1: Representing approved applications.
0: Representing refused applications. This transformation provided a clear and standardized representation of application outcomes.

3. **Creation of the year Variable**

A new variable, year, was created by extracting the year component from the date field. This allowed for an analysis of temporal trends without losing the temporal resolution of the data. The original date variable remained intact for potential use in supplementary analyses.

4. **Filtering Applications from Earlier Years**
Applications before 2016 were removed from the dataset due to their low counts. Retaining these outliers could lead to biased results, particularly in trend analyses or modeling. By excluding these years, the dataset better represents the more recent and consistent patterns of decision-making.

5. **Removing Missing Values**
Records with missing values in the chosen variables (decision, application_type, year, and planning_district) were removed.

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows the model's ability to generate data consistent with the observed data. By overlaying the observed data and simulated replicated datasets  generated from the posterior predictive distribution, we assess the model's adequacy. The close alignment between the observed data and the majority of the simulated replicated datasets indicates that the model captures the underlying structure of the data well. Deviations would signal potential misfits or areas where the model assumptions may need to be revised.

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This comparison highlights how the data influenced parameter estimates. Large shifts from the prior to the posterior, such as seen for certain planning districts and years, suggest strong data-driven updates. Conversely, parameters where the posterior closely resembles the prior indicate minimal influence from the observed data. This evaluation helps assess the informativeness of the priors and the robustness of the parameter estimates, ensuring the model is both data- and prior-consistent.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows he sampled values for each chain of the Markov Chain Monte Carlo (MCMC) simulation over iterations. The chains appear to mix well and explore the parameter space without any evident trends or stickiness, suggesting convergence. The consistent overlap of chains indicates that the posterior distribution has been effectively sampled, reducing the risk of bias due to poor chain mixing or non-convergence.

@fig-stanareyouokay-2 is a Rhat plot. It evaluates the Gelman-Rubin convergence diagnostic. All parameters show $\hat{R}$ values close to 1, which indicates that the between-chain and within-chain variances are nearly identical. This confirms that the MCMC chains have converged and are sampling from the same target distribution, validating the reliability of the posterior estimates.

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(model, "trace")

plot(model, "rhat")
```


## Surveys, Sampling, and Observational Data

### Overview
This appendix delves into the methodological considerations underlying the data used in this paper, focusing on the challenges and intricacies of observational data, the implications of sampling, and the potential use of surveys and simulations to enrich insights.

### Methodology

### Sampling Approach

#### Target Population


#### Sampling Frame



#### Trade-offs



### Idealized Methodology


### Survey



\newpage


# References


